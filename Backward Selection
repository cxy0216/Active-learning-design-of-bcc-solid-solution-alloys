import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold

# --------- è¯»å–æ•°æ® ---------
file_path = r'/content/å±ˆæœå¼ºåº¦ç‰¹å¾PCCç­›é€‰.xlsx'
data = pd.read_excel(file_path)

# --------- ç‰¹å¾ & ç›®æ ‡ ---------
X = data.iloc[:, :-1]  # ç‰¹å¾åˆ—
y = data.iloc[:, -1]   # ç›®æ ‡å˜é‡

# --------- æ•°æ®å½’ä¸€åŒ– ---------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

# è·å–æœ€ä½³è¶…å‚æ•°
best_C = 900.81
best_epsilon = 3.8196
print(f"Initial Best Parameters: C = {best_C}, epsilon = {best_epsilon}")

# --------- è‡ªå®šä¹‰åˆ†ç»„å‡½æ•° ---------
def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    """ æŒ‰ç»„å‡åŒ€åˆ†é…æ ·æœ¬åˆ°æ¯ä¸ªæŠ˜å ä¸­ """
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}

    # åˆ›å»º KFold
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}

    # æŒ‰ç…§æŠ˜å è¿›è¡Œåˆ†é…
    for group in unique_groups:
        group_samples = groups[group]
        # åœ¨æ¯ä¸ªæŠ˜å ä¸­å‡åŒ€åˆ†é…è¯¥ç»„çš„æ ·æœ¬
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])

    # ç¡®ä¿æ¯ä¸ªæŠ˜å çš„æ ·æœ¬åˆ†å¸ƒå‡åŒ€
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

# Define group labels
group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

# --------- åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°å‡½æ•° ---------
def evaluate_model_with_ten_fold_cv(X, y):
    """ä½¿ç”¨åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    all_rmse_results = []
    all_r2_results = []
    all_y_true = []
    all_y_pred = []

    for seed in range(40, 50):  # seeds 40-49
        fold_indices = custom_group_kfold(X, y, group_labels, n_splits=5, random_state=seed)

        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X)), test_idx)
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # è®­ç»ƒæ¨¡å‹
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)

            all_rmse_results.append(rmse)
            all_r2_results.append(r2)
            all_y_true.extend(y_test.tolist())
            all_y_pred.extend(y_pred.tolist())

    # è¿”å›50ä¸ªç»“æœçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥åŠç”¨äºç»˜å›¾çš„é¢„æµ‹å€¼
    mean_rmse = np.mean(all_rmse_results)
    std_rmse = np.std(all_rmse_results)
    mean_r2 = np.mean(all_r2_results)
    std_r2 = np.std(all_r2_results)

    return mean_rmse, std_rmse, mean_r2, std_r2, all_y_true, all_y_pred

# --------- è‡ªåŠ¨ç‰¹å¾åˆ é™¤å¹¶æ›´æ–° ---------
# ç”¨äºä¿å­˜æ¯è½®åˆ é™¤ç‰¹å¾åçš„æ‰€æœ‰ç»“æœ
all_results = []
# ç”¨äºè®°å½•æ¯è½®åˆ é™¤çš„æœ€ä½³ç‰¹å¾åŠå…¶å¯¹åº”çš„æ€§èƒ½
best_features_to_delete = []
rmse_values = []
r2_values = []
rmse_std_values = []
r2_std_values = []

# è®°å½•å…¨å±€æœ€ä½³æ€§èƒ½å’Œå¯¹åº”çš„ç‰¹å¾å­é›†
global_best_rmse = float('inf')
global_best_feature_set = None
global_best_performance = None
feature_sets_performance = []  # è®°å½•æ¯è½®åçš„ç‰¹å¾é›†å’Œæ€§èƒ½

print(f"å¼€å§‹ç‰¹å¾åˆ é™¤è¿‡ç¨‹ï¼Œå½“å‰ç‰¹å¾æ•°: {len(X_scaled.columns)}")
print(f"å›ºå®šä¿ç•™å‰13ä¸ªç‰¹å¾ï¼Œå¯åˆ é™¤ç‰¹å¾æ•°: {len(X_scaled.columns[13:])}")

# è¯„ä¼°åˆå§‹ç‰¹å¾é›†æ€§èƒ½
print(f"\n=== åˆå§‹ç‰¹å¾é›†è¯„ä¼° ===")
initial_rmse, initial_rmse_std, initial_r2, initial_r2_std, _, _ = evaluate_model_with_ten_fold_cv(X_scaled, y)
print(f"åˆå§‹æ€§èƒ½: RMSE={initial_rmse:.4f} Â± {initial_rmse_std:.4f}, RÂ²={initial_r2:.4f} Â± {initial_r2_std:.4f}")

# è®°å½•åˆå§‹ç‰¹å¾é›†
feature_sets_performance.append({
    'Round': 0,
    'Feature_Count': len(X_scaled.columns),
    'Features': list(X_scaled.columns),
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
})

global_best_rmse = initial_rmse
global_best_feature_set = list(X_scaled.columns)
global_best_performance = {
    'Round': 0,
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
}

round_num = 1
while len(X_scaled.columns) > 13:  # ä¿ç•™æœ€å°‘13ä¸ªç‰¹å¾
    print(f"\n=== ç¬¬ {round_num} è½®ç‰¹å¾åˆ é™¤ ===")
    print(f"å½“å‰ç‰¹å¾æ•°: {len(X_scaled.columns)}")

    best_rmse = float('inf')  # åˆå§‹åŒ–ä¸ºæ— ç©·å¤§
    best_r2 = -np.inf  # åˆå§‹åŒ–ä¸ºæ— ç©·å°
    best_feature = None  # åˆå§‹åŒ–ä¸ºç©º
    best_rmse_std = 0
    best_r2_std = 0
    best_y_true = []
    best_y_pred = []

    # å¾ªç¯åˆ é™¤æ¯ä¸ªç‰¹å¾ï¼ˆä»…è€ƒè™‘ç¬¬13åˆ—ä¹‹åçš„ç‰¹å¾ï¼‰
    available_features = X_scaled.columns[13:]
    print(f"å¯åˆ é™¤çš„ç‰¹å¾: {list(available_features)}")

    for i, feature in enumerate(available_features):
        print(f"  æ­£åœ¨è¯„ä¼°åˆ é™¤ç‰¹å¾ '{feature}' ({i+1}/{len(available_features)})...")
        X_temp = X_scaled.drop(columns=[feature])  # åˆ é™¤å½“å‰ç‰¹å¾åˆ—

        # ä½¿ç”¨åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è®¡ç®— RMSE å’Œ RÂ²
        rmse, rmse_std, r2, r2_std, y_true, y_pred = evaluate_model_with_ten_fold_cv(X_temp, y)

        # æ‰“å°å½“å‰åˆ é™¤ç‰¹å¾åçš„ç»“æœ
        print(f"    åˆ é™¤ '{feature}' - RMSE: {rmse:.4f} Â± {rmse_std:.4f}, RÂ²: {r2:.4f} Â± {r2_std:.4f}")

        # æ›´æ–°æœ€ä½³ç»“æœï¼ˆåŸºäºRMSEå‡å€¼ï¼‰
        if rmse < best_rmse:
            best_rmse = rmse
            best_rmse_std = rmse_std
            best_r2 = r2
            best_r2_std = r2_std
            best_feature = feature
            best_y_true = y_true
            best_y_pred = y_pred

        # ä¿å­˜å½“å‰åˆ é™¤ç‰¹å¾çš„æ•ˆæœå’Œå½“å‰ç‰¹å¾æ•°ç›®
        all_results.append({
            'Round': round_num,
            'Removed Feature': feature,
            'RMSE_Mean': rmse,
            'RMSE_Std': rmse_std,
            'R2_Mean': r2,
            'R2_Std': r2_std,
            'Current Features Count': len(X_scaled.columns)
        })

    # è¾“å‡ºæœ€ä½³ç‰¹å¾å’Œå¯¹åº”çš„ RMSE å’Œ RÂ²
    print(f"\n  âœ… æœ€ä½³åˆ é™¤ç‰¹å¾: {best_feature}")
    print(f"  ğŸ“Š æœ€ä½³æ€§èƒ½: RMSE={best_rmse:.4f} Â± {best_rmse_std:.4f}, RÂ²={best_r2:.4f} Â± {best_r2_std:.4f}")

    # å°†æœ€ä½³åˆ é™¤ç‰¹å¾åŠå…¶æ€§èƒ½ä¿å­˜åˆ°å¯¹åº”åˆ—è¡¨
    best_features_to_delete.append(best_feature)
    rmse_values.append(best_rmse)
    r2_values.append(best_r2)
    rmse_std_values.append(best_rmse_std)
    r2_std_values.append(best_r2_std)

    # åˆ é™¤æœ€ä¼˜ç‰¹å¾å¹¶æ›´æ–°æ•°æ®
    X_scaled = X_scaled.drop(columns=[best_feature])

    # è®°å½•åˆ é™¤åçš„ç‰¹å¾é›†å’Œæ€§èƒ½
    feature_sets_performance.append({
        'Round': round_num,
        'Feature_Count': len(X_scaled.columns),
        'Features': list(X_scaled.columns),
        'RMSE_Mean': best_rmse,
        'RMSE_Std': best_rmse_std,
        'R2_Mean': best_r2,
        'R2_Std': best_r2_std
    })

    # æ›´æ–°å…¨å±€æœ€ä½³æ€§èƒ½
    if best_rmse < global_best_rmse:
        global_best_rmse = best_rmse
        global_best_feature_set = list(X_scaled.columns)
        global_best_performance = {
            'Round': round_num,
            'RMSE_Mean': best_rmse,
            'RMSE_Std': best_rmse_std,
            'R2_Mean': best_r2,
            'R2_Std': best_r2_std,
            'Removed_Feature': best_feature
        }
        print(f"  ğŸŒŸ å‘ç°æ–°çš„å…¨å±€æœ€ä½³æ€§èƒ½ï¼")

    # ç»˜åˆ¶å®é™…å€¼ä¸é¢„æµ‹å€¼çš„å¯¹æ¯”å›¾ï¼ˆä½¿ç”¨æœ€ä½³åˆ é™¤ç‰¹å¾åçš„ç»“æœï¼‰
    plt.figure(figsize=(8, 6))
    plt.scatter(best_y_true, best_y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Round {round_num}: After Removing '{best_feature}'\n" +
              f"RMSE={best_rmse:.4f} Â± {best_rmse_std:.4f}, RÂ²={best_r2:.4f} Â± {best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    round_num += 1

print(f"\nğŸ‰ ç‰¹å¾åˆ é™¤å®Œæˆï¼")
print(f"æœ€ç»ˆä¿ç•™ç‰¹å¾æ•°: {len(X_scaled.columns)}")
print(f"æœ€ç»ˆä¿ç•™çš„ç‰¹å¾: {list(X_scaled.columns)}")

# æ˜¾ç¤ºå…¨å±€æœ€ä½³æ€§èƒ½
print(f"\nğŸŒŸ å…¨å±€æœ€ä½³æ€§èƒ½:")
print(f"è½®æ¬¡: {global_best_performance['Round']}")
print(f"ç‰¹å¾æ•°: {len(global_best_feature_set)}")
print(f"RMSE: {global_best_performance['RMSE_Mean']:.4f} Â± {global_best_performance['RMSE_Std']:.4f}")
print(f"RÂ²: {global_best_performance['R2_Mean']:.4f} Â± {global_best_performance['R2_Std']:.4f}")
print(f"æœ€ä½³ç‰¹å¾é›†: {global_best_feature_set}")

# å°†ç»“æœä¿å­˜åˆ° DataFrame ä¸­
all_results_df = pd.DataFrame(all_results)

# ä¿å­˜åˆ°åŸ Excel æ–‡ä»¶
output_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦ç‰¹å¾ç­›é€‰ç»“æœ.xlsx'
all_results_df.to_excel(output_file, index=False)

# **ä¿å­˜æœ€ä½³åˆ é™¤ç‰¹å¾åŠå…¶æ€§èƒ½åˆ°å¦ä¸€ä¸ªExcelæ–‡ä»¶**
best_features_df = pd.DataFrame({
    'Round': range(1, len(best_features_to_delete) + 1),
    'Best Feature to Delete': best_features_to_delete,
    'Best RMSE Mean': rmse_values,
    'Best RMSE Std': rmse_std_values,
    'Best RÂ² Mean': r2_values,
    'Best RÂ² Std': r2_std_values,
    'Remaining Features': [len(X_scaled.columns) + len(best_features_to_delete) - i
                          for i in range(len(best_features_to_delete))]
})

# ä¿å­˜æœ€ä½³åˆ é™¤ç‰¹å¾åˆ°æ–°çš„æ–‡ä»¶
best_features_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦æœ€ä½³åˆ é™¤ç‰¹å¾.xlsx'
best_features_df.to_excel(best_features_file, index=False)

# **ä¿å­˜æ¯è½®ç‰¹å¾é›†æ€§èƒ½å¯¹æ¯”**
feature_sets_df = pd.DataFrame(feature_sets_performance)
feature_sets_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦ç‰¹å¾é›†æ€§èƒ½å¯¹æ¯”.xlsx'
feature_sets_df.to_excel(feature_sets_file, index=False)

# **ä¿å­˜å…¨å±€æœ€ä½³ç‰¹å¾å­é›†**
best_subset_info = pd.DataFrame({
    'Metric': ['Round', 'Feature_Count', 'RMSE_Mean', 'RMSE_Std', 'R2_Mean', 'R2_Std'],
    'Value': [
        global_best_performance['Round'],
        len(global_best_feature_set),
        global_best_performance['RMSE_Mean'],
        global_best_performance['RMSE_Std'],
        global_best_performance['R2_Mean'],
        global_best_performance['R2_Std']
    ]
})

best_features_list = pd.DataFrame({
    'Feature_Index': range(len(global_best_feature_set)),
    'Feature_Name': global_best_feature_set
})

# ä¿å­˜æœ€ä½³ç‰¹å¾å­é›†åˆ°æ–°çš„Excelæ–‡ä»¶
best_subset_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦æœ€ä½³ç‰¹å¾å­é›†.xlsx'
with pd.ExcelWriter(best_subset_file, engine='openpyxl') as writer:
    best_subset_info.to_excel(writer, sheet_name='Performance_Info', index=False)
    best_features_list.to_excel(writer, sheet_name='Feature_List', index=False)

print(f"\nğŸ“ ç»“æœå·²ä¿å­˜:")
print(f"  è¯¦ç»†ç»“æœ: {output_file}")
print(f"  æœ€ä½³åˆ é™¤ç‰¹å¾: {best_features_file}")
print(f"  ç‰¹å¾é›†æ€§èƒ½å¯¹æ¯”: {feature_sets_file}")
print(f"  æœ€ä½³ç‰¹å¾å­é›†: {best_subset_file}")

# æ˜¾ç¤ºåˆ é™¤é¡ºåºæ‘˜è¦
print(f"\nğŸ“‹ ç‰¹å¾åˆ é™¤é¡ºåºæ‘˜è¦:")
for i, (feature, rmse, rmse_std, r2, r2_std) in enumerate(zip(
    best_features_to_delete, rmse_values, rmse_std_values, r2_values, r2_std_values)):
    print(f"  ç¬¬{i+1}è½®: åˆ é™¤ '{feature}' -> RMSE={rmse:.4f}Â±{rmse_std:.4f}, RÂ²={r2:.4f}Â±{r2_std:.4f}")

# æ˜¾ç¤ºæ¯è½®æ€§èƒ½å˜åŒ–
print(f"\nğŸ“Š æ¯è½®æ€§èƒ½å˜åŒ–:")
for perf in feature_sets_performance:
    status = "ğŸŒŸ æœ€ä½³" if perf['Round'] == global_best_performance['Round'] else ""
    print(f"  è½®æ¬¡{perf['Round']:2d}: {perf['Feature_Count']:2d}ä¸ªç‰¹å¾ -> RMSE={perf['RMSE_Mean']:.4f}Â±{perf['RMSE_Std']:.4f}, RÂ²={perf['R2_Mean']:.4f}Â±{perf['R2_Std']:.4f} {status}")

print(f"\nğŸ” æœ€ç»ˆæ¨¡å‹æ€§èƒ½è¯„ä¼°...")
final_rmse, final_rmse_std, final_r2, final_r2_std, final_y_true, final_y_pred = evaluate_model_with_ten_fold_cv(X_scaled, y)
print(f"æœ€ç»ˆæ¨¡å‹ - 10x5-Fold CV RMSE = {final_rmse:.4f} Â± {final_rmse_std:.4f}")
print(f"æœ€ç»ˆæ¨¡å‹ - 10x5-Fold CV RÂ² = {final_r2:.4f} Â± {final_r2_std:.4f}")

# ç»˜åˆ¶æœ€ç»ˆæ¨¡å‹çš„é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 8))
plt.scatter(final_y_true, final_y_pred, color='green', alpha=0.6, label='Final Model')
plt.plot([min(final_y_true), max(final_y_true)], [min(final_y_true), max(final_y_true)],
         color='red', linestyle='--', label='Perfect Prediction')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f"Final Model Performance\n" +
          f"Features: {len(X_scaled.columns)}, RMSE={final_rmse:.4f}Â±{final_rmse_std:.4f}, RÂ²={final_r2:.4f}Â±{final_r2_std:.4f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ç»˜åˆ¶å…¨å±€æœ€ä½³ç‰¹å¾å­é›†çš„æ€§èƒ½ï¼ˆå¦‚æœä¸æ˜¯æœ€ç»ˆæ¨¡å‹ï¼‰
if global_best_performance['Round'] != round_num - 1:
    print(f"\nğŸ¯ ä½¿ç”¨å…¨å±€æœ€ä½³ç‰¹å¾å­é›†è¿›è¡Œç‹¬ç«‹è¯„ä¼°...")
    # é‡æ–°æ„å»ºæœ€ä½³ç‰¹å¾å­é›†
    X_best_subset = X.iloc[:, :13].copy()  # å‰13ä¸ªå›ºå®šç‰¹å¾
    for feature in global_best_feature_set[13:]:  # æ·»åŠ æœ€ä½³å­é›†ä¸­çš„å…¶ä»–ç‰¹å¾
        if feature in X.columns:
            X_best_subset[feature] = X[feature]

    # æ ‡å‡†åŒ–
    X_best_scaled = scaler.fit_transform(X_best_subset)
    X_best_scaled = pd.DataFrame(X_best_scaled, columns=X_best_subset.columns)

    # è¯„ä¼°æ€§èƒ½
    best_rmse, best_rmse_std, best_r2, best_r2_std, best_y_true, best_y_pred = evaluate_model_with_ten_fold_cv(X_best_scaled, y)

    print(f"æœ€ä½³ç‰¹å¾å­é›†ç‹¬ç«‹è¯„ä¼°:")
    print(f"RMSE = {best_rmse:.4f} Â± {best_rmse_std:.4f}")
    print(f"RÂ² = {best_r2:.4f} Â± {best_r2_std:.4f}")

    # ç»˜åˆ¶æœ€ä½³ç‰¹å¾å­é›†çš„é¢„æµ‹ç»“æœ
    plt.figure(figsize=(10, 8))
    plt.scatter(best_y_true, best_y_pred, color='gold', alpha=0.6, label='Best Feature Subset')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Best Feature Subset Performance (Round {global_best_performance['Round']})\n" +
              f"Features: {len(global_best_feature_set)}, RMSE={best_rmse:.4f}Â±{best_rmse_std:.4f}, RÂ²={best_r2:.4f}Â±{best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
