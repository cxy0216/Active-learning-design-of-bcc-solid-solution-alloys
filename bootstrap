import pandas as pd
import numpy as np
from sklearn.svm import SVR
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class SVRBootstrapEnsemble:
    def __init__(self, n_estimators=1000, C=900.81, epsilon=3.8196, random_state=42):
        self.n_estimators = n_estimators
        self.C = C
        self.epsilon = epsilon
        self.random_state = random_state
        self.models = []
        self.scalers_X = []
        self.is_fitted = False
        self.model_metrics = []

    def _bootstrap_sample(self, X, y):
        n_samples = len(X)
        indices = np.random.choice(n_samples, size=n_samples, replace=True)
        X_boot = X[indices]
        y_boot = y[indices]
        oob_mask = np.ones(n_samples, dtype=bool)
        oob_mask[np.unique(indices)] = False
        oob_indices = np.where(oob_mask)[0]
        if len(oob_indices) > 0:
            X_oob = X[oob_indices]
            y_oob = y[oob_indices]
        else:
            X_oob = np.array([]).reshape(0, X.shape[1])
            y_oob = np.array([])
        return X_boot, y_boot, X_oob, y_oob, oob_indices

    def _calculate_metrics(self, y_true, y_pred):
        mae = mean_absolute_error(y_true, y_pred)
        mse = mean_squared_error(y_true, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_true, y_pred)
        return mae, mse, rmse, r2

    def fit(self, X, y, show_progress=10, save_excel=True, excel_path="yield_strength_model_metrics.xlsx"):
        X = np.array(X)
        y = np.array(y)
        np.random.seed(self.random_state)
        oob_predictions = np.full((len(X), self.n_estimators), np.nan)
        oob_counts = np.zeros(len(X))
        self.model_metrics = []

        for i in tqdm(range(self.n_estimators), desc="Training models"):
            X_boot, y_boot, X_oob, y_oob, oob_indices = self._bootstrap_sample(X, y)
            if len(X_boot) == 0:
                continue

            scaler_X = StandardScaler()
            X_boot_scaled = scaler_X.fit_transform(X_boot)
            y_boot_original = y_boot

            svr = SVR(C=self.C, epsilon=self.epsilon, kernel='rbf')
            svr.fit(X_boot_scaled, y_boot_original)

            self.models.append(svr)
            self.scalers_X.append(scaler_X)

            y_train_pred = svr.predict(X_boot_scaled)
            train_mae, train_mse, train_rmse, train_r2 = self._calculate_metrics(y_boot_original, y_train_pred)

            current_metrics = {
                'Model': i + 1,
                'Train_Samples': len(y_boot),
                'Train_MAE': train_mae,
                'Train_MSE': train_mse,
                'Train_RMSE': train_rmse,
                'Train_R2': train_r2,
                'OOB_Samples': len(y_oob),
                'OOB_MAE': np.nan,
                'OOB_MSE': np.nan,
                'OOB_RMSE': np.nan,
                'OOB_R2': np.nan
            }

            if len(X_oob) > 0:
                X_oob_scaled = scaler_X.transform(X_oob)
                y_oob_pred = svr.predict(X_oob_scaled)
                oob_mae, oob_mse, oob_rmse, oob_r2 = self._calculate_metrics(y_oob, y_oob_pred)
                current_metrics.update({
                    'OOB_MAE': oob_mae,
                    'OOB_MSE': oob_mse,
                    'OOB_RMSE': oob_rmse,
                    'OOB_R2': oob_r2
                })
                oob_predictions[oob_indices, i] = y_oob_pred
                oob_counts[oob_indices] += 1

            self.model_metrics.append(current_metrics)

        valid_mask = oob_counts > 0
        if np.sum(valid_mask) > 0:
            oob_pred_mean = np.nanmean(oob_predictions[valid_mask], axis=1)
            y_oob_true = y[valid_mask]
            self.oob_mae = mean_absolute_error(y_oob_true, oob_pred_mean)
            self.oob_mse = mean_squared_error(y_oob_true, oob_pred_mean)
            self.oob_rmse = np.sqrt(self.oob_mse)
            self.oob_r2 = r2_score(y_oob_true, oob_pred_mean)
            self.oob_true = y_oob_true
            self.oob_pred = oob_pred_mean
        else:
            self.oob_mae = self.oob_mse = self.oob_rmse = self.oob_r2 = None
            self.oob_true = self.oob_pred = None

        if save_excel:
            self.save_metrics_to_excel(excel_path)

        self.is_fitted = True

    def save_metrics_to_excel(self, excel_path):
        try:
            df_metrics = pd.DataFrame(self.model_metrics)
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                df_metrics.to_excel(writer, sheet_name='All_Models', index=False)
                summary_stats = df_metrics.describe()
                summary_stats.to_excel(writer, sheet_name='Summary_Stats')
                best_models_oob = df_metrics.dropna(subset=['OOB_R2']).nlargest(10, 'OOB_R2')
                best_models_oob.to_excel(writer, sheet_name='Top10_OOB_R2', index=False)
                worst_models_oob = df_metrics.dropna(subset=['OOB_R2']).nsmallest(10, 'OOB_R2')
                worst_models_oob.to_excel(writer, sheet_name='Bottom10_OOB_R2', index=False)
        except Exception as e:
            pass

    def predict(self, X, return_std=False):
        if not self.is_fitted:
            raise ValueError("Model not fitted")
        X = np.array(X)
        predictions = []
        for i, (model, scaler_X) in enumerate(zip(self.models, self.scalers_X)):
            X_scaled = scaler_X.transform(X)
            y_pred = model.predict(X_scaled)
            predictions.append(y_pred)
        predictions = np.array(predictions)
        mean_pred = np.mean(predictions, axis=0)
        if return_std:
            std_pred = np.std(predictions, axis=0)
            return mean_pred, std_pred
        return mean_pred

    def predict_with_interval(self, X, confidence=0.95):
        if not self.is_fitted:
            raise ValueError("Model not fitted")
        X = np.array(X)
        predictions = []
        for model, scaler_X in zip(self.models, self.scalers_X):
            X_scaled = scaler_X.transform(X)
            y_pred = model.predict(X_scaled)
            predictions.append(y_pred)
        predictions = np.array(predictions)
        mean_pred = np.mean(predictions, axis=0)
        alpha = 1 - confidence
        lower_percentile = (alpha / 2) * 100
        upper_percentile = (1 - alpha / 2) * 100
        lower_bound = np.percentile(predictions, lower_percentile, axis=0)
        upper_bound = np.percentile(predictions, upper_percentile, axis=0)
        return mean_pred, lower_bound, upper_bound

def plot_metrics_analysis(ensemble):
    if not ensemble.model_metrics:
        return
    df_metrics = pd.DataFrame(ensemble.model_metrics)
    oob_data = df_metrics.dropna(subset=['OOB_R2'])
    plt.figure(figsize=(20, 12))

    plt.subplot(2, 4, 1)
    plt.hist(df_metrics['Train_R2'], bins=50, alpha=0.7, color='blue', edgecolor='black')
    plt.xlabel('Train R²')
    plt.ylabel('Frequency')
    plt.title('Distribution of Train R²')
    plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 2)
    if len(oob_data) > 0:
        plt.hist(oob_data['OOB_R2'], bins=50, alpha=0.7, color='red', edgecolor='black')
        plt.xlabel('OOB R²')
        plt.ylabel('Frequency')
        plt.title('Distribution of OOB R²')
        plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 3)
    if len(oob_data) > 0:
        plt.scatter(oob_data['Train_R2'], oob_data['OOB_R2'], alpha=0.6, color='green')
        plt.xlabel('Train R²')
        plt.ylabel('OOB R²')
        plt.title('Train vs OOB R²')
        plt.plot([0, 1], [0, 1], 'r--', alpha=0.8)
        plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 4)
    if len(oob_data) > 0:
        plt.scatter(oob_data['Train_RMSE'], oob_data['OOB_RMSE'], alpha=0.6, color='purple')
        plt.xlabel('Train RMSE')
        plt.ylabel('OOB RMSE')
        plt.title('Train vs OOB RMSE')
        plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 5)
    plt.plot(df_metrics['Model'], df_metrics['Train_R2'], 'b-', alpha=0.7, label='Train R²')
    if len(oob_data) > 0:
        plt.plot(oob_data['Model'], oob_data['OOB_R2'], 'r-', alpha=0.7, label='OOB R²')
    plt.xlabel('Model Number')
    plt.ylabel('R²')
    plt.title('R² vs Model Number')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 6)
    plt.hist(df_metrics['Train_Samples'], bins=30, alpha=0.7, color='orange', edgecolor='black')
    plt.xlabel('Training Samples')
    plt.ylabel('Frequency')
    plt.title('Distribution of Training Sample Counts')
    plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 7)
    oob_samples = df_metrics[df_metrics['OOB_Samples'] > 0]['OOB_Samples']
    if len(oob_samples) > 0:
        plt.hist(oob_samples, bins=30, alpha=0.7, color='brown', edgecolor='black')
        plt.xlabel('OOB Samples')
        plt.ylabel('Frequency')
        plt.title('Distribution of OOB Sample Counts')
        plt.grid(True, alpha=0.3)

    plt.subplot(2, 4, 8)
    if len(oob_data) > 0:
        data_to_plot = [df_metrics['Train_R2'], oob_data['OOB_R2']]
        plt.boxplot(data_to_plot, labels=['Train R²', 'OOB R²'])
        plt.ylabel('R²')
        plt.title('R² Performance Comparison')
        plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

def load_and_preprocess_data(file_path):
    df = pd.read_excel(file_path)
    df_clean = df.dropna()
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()
    df_numeric = df_clean[numeric_cols]
    target_col = None
    for col in df_numeric.columns:
        if 'yield' in str(col).lower() or 'strength' in str(col).lower():
            target_col = col
            break
    if target_col is None:
        target_col = df_numeric.columns[-1]
    feature_cols = [col for col in df_numeric.columns if col != target_col]
    X = df_numeric[feature_cols].values
    y = df_numeric[target_col].values
    return X, y, feature_cols, target_col

def plot_results(y_true, y_pred, lower_bound=None, upper_bound=None, title="SVR Bootstrap Results"):
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.scatter(y_true, y_pred, alpha=0.6, color='blue')
    if lower_bound is not None and upper_bound is not None:
        plt.errorbar(y_true, y_pred, yerr=[y_pred - lower_bound, upper_bound - y_pred], fmt='o', alpha=0.3, capsize=2, color='blue')
    min_val = min(y_true.min(), y_pred.min())
    max_val = max(y_true.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')
    plt.xlabel('Actual Yield Strength')
    plt.ylabel('Predicted Yield Strength')
    plt.title('Predicted vs Actual')
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 2)
    residuals = y_true - y_pred
    plt.scatter(y_pred, residuals, alpha=0.6, color='green')
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Predicted Yield Strength')
    plt.ylabel('Residuals')
    plt.title('Residual Plot')
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 3)
    plt.hist(residuals, bins=30, alpha=0.7, color='orange', edgecolor='black')
    plt.xlabel('Residuals')
    plt.ylabel('Frequency')
    plt.title('Residual Distribution')
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.suptitle(title, y=1.02, fontsize=16)
    plt.show()

def plot_oob_results(ensemble):
    if ensemble.oob_true is None or ensemble.oob_pred is None:
        return
    plot_results(ensemble.oob_true, ensemble.oob_pred, title="Out-of-Bag (OOB) Evaluation Results")

def main():
    file_path = '/content/yield_strength_features_final.xlsx'
    try:
        X, y, feature_cols, target_col = load_and_preprocess_data(file_path)
        ensemble = SVRBootstrapEnsemble(n_estimators=1000, C=900.81, epsilon=3.8196, random_state=42)
        ensemble.fit(X, y, show_progress=50, save_excel=True, excel_path="bootstrap_svr_metrics.xlsx")
        if ensemble.oob_true is not None:
            plot_oob_results(ensemble)
        plot_metrics_analysis(ensemble)
        sample_indices = np.random.choice(len(X), size=min(10, len(X)), replace=False)
        X_sample = X[sample_indices]
        y_sample = y[sample_indices]
        y_pred_sample, lower_sample, upper_sample = ensemble.predict_with_interval(X_sample, confidence=0.95)
        return ensemble
    except Exception as e:
        return None

if __name__ == "__main__":
    ensemble_model = main()
