import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from itertools import combinations
import time

file_path = r'/content/yield_strength_features_exhaustive.xlsx'
data = pd.read_excel(file_path)

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

best_C = 900.81
best_epsilon = 3.8196

def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}
    for group in unique_groups:
        group_samples = groups[group]
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

def evaluate_model_with_ten_fold_cv(X, y):
    all_rmse_results = []
    all_r2_results = []
    for seed in range(40, 50):
        fold_indices = custom_group_kfold(X, y, group_labels, n_splits=5, random_state=seed)
        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X)), test_idx)
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            all_rmse_results.append(rmse)
            all_r2_results.append(r2)
    mean_rmse = np.mean(all_rmse_results)
    std_rmse = np.std(all_rmse_results)
    mean_r2 = np.mean(all_r2_results)
    std_r2 = np.std(all_r2_results)
    return mean_rmse, std_rmse, mean_r2, std_r2

fixed_features = list(X_scaled.columns[:13])
candidate_features = list(X_scaled.columns[13:])

total_combinations = 0
for r in range(len(candidate_features) + 1):
    total_combinations += len(list(combinations(candidate_features, r)))

all_results = []
best_global_rmse = float('inf')
best_global_feature_set = None
best_global_performance = None

start_time = time.time()
combination_count = 0

for r in range(len(candidate_features) + 1):
    if r == 0:
        feature_combinations = [()]
    else:
        feature_combinations = list(combinations(candidate_features, r))

    for i, selected_candidates in enumerate(feature_combinations):
        combination_count += 1
        current_features = fixed_features + list(selected_candidates)
        X_current = X_scaled[current_features]
        rmse, rmse_std, r2, r2_std = evaluate_model_with_ten_fold_cv(X_current, y)

        result = {
            'Combination_ID': combination_count,
            'Total_Features': len(current_features),
            'Fixed_Features': len(fixed_features),
            'Selected_Candidates': len(selected_candidates),
            'Selected_Candidate_Names': list(selected_candidates),
            'All_Features': current_features,
            'RMSE_Mean': rmse,
            'RMSE_Std': rmse_std,
            'R2_Mean': r2,
            'R2_Std': r2_std
        }
        all_results.append(result)

        if rmse < best_global_rmse:
            best_global_rmse = rmse
            best_global_feature_set = current_features.copy()
            best_global_performance = result.copy()

results_df = pd.DataFrame(all_results)
results_df_sorted = results_df.sort_values('RMSE_Mean').reset_index(drop=True)

output_file = '/content/drive/MyDrive/HEA_data/exhaustive_results.xlsx'
results_df_sorted.to_excel(output_file, index=False)

top_results = results_df_sorted.head(20)
top_results_file = '/content/drive/MyDrive/HEA_data/exhaustive_top20.xlsx'
top_results.to_excel(top_results_file, index=False)

best_subset_info = pd.DataFrame({
    'Metric': ['Combination_ID', 'Total_Features', 'Selected_Candidates', 'RMSE_Mean', 'RMSE_Std', 'R2_Mean', 'R2_Std'],
    'Value': [
        best_global_performance['Combination_ID'],
        best_global_performance['Total_Features'],
        best_global_performance['Selected_Candidates'],
        best_global_performance['RMSE_Mean'],
        best_global_performance['RMSE_Std'],
        best_global_performance['R2_Mean'],
        best_global_performance['R2_Std']
    ]
})

best_features_list = pd.DataFrame({
    'Feature_Type': ['Fixed'] * len(fixed_features) + ['Selected'] * len(best_global_performance['Selected_Candidate_Names']),
    'Feature_Name': fixed_features + best_global_performance['Selected_Candidate_Names']
})

best_combination_file = '/content/drive/MyDrive/HEA_data/exhaustive_best_combination.xlsx'
with pd.ExcelWriter(best_combination_file, engine='openpyxl') as writer:
    best_subset_info.to_excel(writer, sheet_name='Performance_Info', index=False)
    best_features_list.to_excel(writer, sheet_name='Feature_List', index=False)

feature_count_analysis = results_df.groupby('Total_Features').agg({
    'RMSE_Mean': ['count', 'mean', 'min', 'max', 'std'],
    'R2_Mean': ['mean', 'min', 'max']
}).round(4)

best_by_feature_count = results_df.loc[results_df.groupby('Total_Features')['RMSE_Mean'].idxmin()]

plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
feature_counts = results_df['Total_Features'].values
rmse_values = results_df['RMSE_Mean'].values
plt.scatter(feature_counts, rmse_values, alpha=0.6, s=20)
plt.plot(best_by_feature_count['Total_Features'], best_by_feature_count['RMSE_Mean'], 'r-o', label='Best per feature count')
plt.xlabel('Number of Features')
plt.ylabel('RMSE')
plt.title('RMSE vs Number of Features')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(2, 2, 2)
r2_values = results_df['R2_Mean'].values
plt.scatter(feature_counts, r2_values, alpha=0.6, s=20)
plt.plot(best_by_feature_count['Total_Features'], best_by_feature_count['R2_Mean'], 'r-o', label='Best per feature count')
plt.xlabel('Number of Features')
plt.ylabel('R²')
plt.title('R² vs Number of Features')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(2, 2, 3)
plt.hist(rmse_values, bins=30, alpha=0.7, edgecolor='black')
plt.axvline(best_global_performance['RMSE_Mean'], color='red', linestyle='--', label=f'Best: {best_global_performance["RMSE_Mean"]:.4f}')
plt.xlabel('RMSE')
plt.ylabel('Frequency')
plt.title('RMSE Distribution')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(2, 2, 4)
top_20 = results_df_sorted.head(20)
plt.bar(range(len(top_20)), top_20['RMSE_Mean'], alpha=0.7)
plt.xlabel('Rank')
plt.ylabel('RMSE')
plt.title('Top 20 Best Results')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

X_best = X_scaled[best_global_feature_set]
final_rmse, final_rmse_std, final_r2, final_r2_std = evaluate_model_with_ten_fold_cv(X_best, y)

all_y_true = []
all_y_pred = []

for seed in range(40, 50):
    fold_indices = custom_group_kfold(X_best, y, group_labels, n_splits=5, random_state=seed)
    for fold, test_idx in fold_indices.items():
        train_idx = np.setdiff1d(np.arange(len(X_best)), test_idx)
        X_train, X_test = X_best.iloc[train_idx], X_best.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        all_y_true.extend(y_test.tolist())
        all_y_pred.extend(y_pred.tolist())

plt.figure(figsize=(10, 8))
plt.scatter(all_y_true, all_y_pred, color='gold', alpha=0.6, label='Best Feature Combination')
plt.plot([min(all_y_true), max(all_y_true)], [min(all_y_true), max(all_y_true)], color='red', linestyle='--', label='Perfect Prediction')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f"Best Feature Combination Performance (Exhaustive Search)\nFeatures: {len(best_global_feature_set)}, RMSE={final_rmse:.4f}±{final_rmse_std:.4f}, R²={final_r2:.4f}±{final_r2_std:.4f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
