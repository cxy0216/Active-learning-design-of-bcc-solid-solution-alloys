import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from itertools import combinations
import time

# --------- è¯»å–æ•°æ® ---------
file_path = r'/content/å±ˆæœå¼ºåº¦ç‰¹å¾ç©·ä¸¾æ¶ˆé™¤.xlsx'
data = pd.read_excel(file_path)

# --------- ç‰¹å¾ & ç›®æ ‡ ---------
X = data.iloc[:, :-1]  # ç‰¹å¾åˆ—
y = data.iloc[:, -1]   # ç›®æ ‡å˜é‡

# --------- æ•°æ®å½’ä¸€åŒ– ---------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

# è·å–æœ€ä½³è¶…å‚æ•°
best_C = 900.81
best_epsilon = 3.8196
print(f"Initial Best Parameters: C = {best_C}, epsilon = {best_epsilon}")

# --------- è‡ªå®šä¹‰åˆ†ç»„å‡½æ•° ---------
def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    """ æŒ‰ç»„å‡åŒ€åˆ†é…æ ·æœ¬åˆ°æ¯ä¸ªæŠ˜å ä¸­ """
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}

    # åˆ›å»º KFold
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}

    # æŒ‰ç…§æŠ˜å è¿›è¡Œåˆ†é…
    for group in unique_groups:
        group_samples = groups[group]
        # åœ¨æ¯ä¸ªæŠ˜å ä¸­å‡åŒ€åˆ†é…è¯¥ç»„çš„æ ·æœ¬
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])

    # ç¡®ä¿æ¯ä¸ªæŠ˜å çš„æ ·æœ¬åˆ†å¸ƒå‡åŒ€
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

# Define group labels
group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

# --------- åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°å‡½æ•° ---------
def evaluate_model_with_ten_fold_cv(X, y):
    """ä½¿ç”¨åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    all_rmse_results = []
    all_r2_results = []

    for seed in range(40, 50):  # seeds 40-49
        fold_indices = custom_group_kfold(X, y, group_labels, n_splits=5, random_state=seed)

        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X)), test_idx)
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # è®­ç»ƒæ¨¡å‹
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)

            all_rmse_results.append(rmse)
            all_r2_results.append(r2)

    # è¿”å›50ä¸ªç»“æœçš„å‡å€¼å’Œæ ‡å‡†å·®
    mean_rmse = np.mean(all_rmse_results)
    std_rmse = np.std(all_rmse_results)
    mean_r2 = np.mean(all_r2_results)
    std_r2 = np.std(all_r2_results)

    return mean_rmse, std_rmse, mean_r2, std_r2

# --------- ç©·ä¸¾æ¶ˆé™¤ç‰¹å¾é€‰æ‹© ---------
# å›ºå®šå‰13ä¸ªç‰¹å¾ï¼Œå¯¹åé¢çš„ç‰¹å¾è¿›è¡Œç©·ä¸¾æ¶ˆé™¤
fixed_features = list(X_scaled.columns[:13])
candidate_features = list(X_scaled.columns[13:])

print(f"å¼€å§‹ç©·ä¸¾æ¶ˆé™¤ç‰¹å¾é€‰æ‹©")
print(f"å›ºå®šç‰¹å¾æ•°: {len(fixed_features)}")
print(f"å€™é€‰ç‰¹å¾æ•°: {len(candidate_features)}")
print(f"å›ºå®šç‰¹å¾: {fixed_features}")
print(f"å€™é€‰ç‰¹å¾: {candidate_features}")

# è®¡ç®—æ‰€æœ‰å¯èƒ½çš„ç»„åˆæ•°é‡
total_combinations = 0
for r in range(len(candidate_features) + 1):  # ä»0ä¸ªåˆ°å…¨éƒ¨å€™é€‰ç‰¹å¾
    total_combinations += len(list(combinations(candidate_features, r)))

print(f"æ€»å…±éœ€è¦è¯„ä¼°çš„ç»„åˆæ•°: {total_combinations}")
print(f"é¢„è®¡è¿è¡Œæ—¶é—´: çº¦ {total_combinations * 2 / 60:.1f} åˆ†é’Ÿï¼ˆå‡è®¾æ¯ä¸ªç»„åˆ2ç§’ï¼‰")

# ç”¨æˆ·ç¡®è®¤
print("\nâš ï¸  è­¦å‘Šï¼šç©·ä¸¾æœç´¢å°†è¯„ä¼°æ‰€æœ‰å¯èƒ½çš„ç‰¹å¾ç»„åˆï¼Œå¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼")
confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
if confirm.lower() != 'y':
    print("å·²å–æ¶ˆç©·ä¸¾æœç´¢")
    exit()

# å­˜å‚¨æ‰€æœ‰ç»“æœ
all_results = []
best_global_rmse = float('inf')
best_global_feature_set = None
best_global_performance = None

start_time = time.time()
combination_count = 0

print(f"\nğŸš€ å¼€å§‹ç©·ä¸¾æœç´¢...")

# éå†æ‰€æœ‰å¯èƒ½çš„å€™é€‰ç‰¹å¾ç»„åˆ
for r in range(len(candidate_features) + 1):  # ä»0ä¸ªåˆ°å…¨éƒ¨å€™é€‰ç‰¹å¾
    print(f"\n=== è¯„ä¼°åŒ…å« {r} ä¸ªå€™é€‰ç‰¹å¾çš„ç»„åˆ ===")

    if r == 0:
        # åªä½¿ç”¨å›ºå®šç‰¹å¾
        feature_combinations = [()]
    else:
        feature_combinations = list(combinations(candidate_features, r))

    print(f"è¯¥ç»„åˆå¤§å°çš„æ•°é‡: {len(feature_combinations)}")

    for i, selected_candidates in enumerate(feature_combinations):
        combination_count += 1

        # æ„å»ºå½“å‰ç‰¹å¾é›†ï¼ˆå›ºå®šç‰¹å¾ + é€‰ä¸­çš„å€™é€‰ç‰¹å¾ï¼‰
        current_features = fixed_features + list(selected_candidates)
        X_current = X_scaled[current_features]

        # è¯„ä¼°å½“å‰ç‰¹å¾ç»„åˆ
        rmse, rmse_std, r2, r2_std = evaluate_model_with_ten_fold_cv(X_current, y)

        # è®°å½•ç»“æœ
        result = {
            'Combination_ID': combination_count,
            'Total_Features': len(current_features),
            'Fixed_Features': len(fixed_features),
            'Selected_Candidates': len(selected_candidates),
            'Selected_Candidate_Names': list(selected_candidates),
            'All_Features': current_features,
            'RMSE_Mean': rmse,
            'RMSE_Std': rmse_std,
            'R2_Mean': r2,
            'R2_Std': r2_std
        }
        all_results.append(result)

        # æ›´æ–°å…¨å±€æœ€ä½³ç»“æœ
        if rmse < best_global_rmse:
            best_global_rmse = rmse
            best_global_feature_set = current_features.copy()
            best_global_performance = result.copy()
            print(f"  ğŸŒŸ å‘ç°æ–°çš„å…¨å±€æœ€ä½³! ç»„åˆ {combination_count}: {len(current_features)}ä¸ªç‰¹å¾, RMSE={rmse:.4f}Â±{rmse_std:.4f}")

        # æ˜¾ç¤ºè¿›åº¦
        if combination_count % 50 == 0 or combination_count <= 10:
            elapsed_time = time.time() - start_time
            avg_time_per_combination = elapsed_time / combination_count
            estimated_total_time = avg_time_per_combination * total_combinations
            remaining_time = estimated_total_time - elapsed_time

            print(f"  è¿›åº¦: {combination_count}/{total_combinations} ({100*combination_count/total_combinations:.1f}%)")
            print(f"  å½“å‰ç»„åˆ: {len(current_features)}ä¸ªç‰¹å¾, RMSE={rmse:.4f}Â±{rmse_std:.4f}")
            print(f"  å·²ç”¨æ—¶é—´: {elapsed_time/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {remaining_time/60:.1f}åˆ†é’Ÿ")

print(f"\nğŸ‰ ç©·ä¸¾æœç´¢å®Œæˆï¼")
print(f"æ€»è®¡è¯„ä¼°äº† {combination_count} ä¸ªç‰¹å¾ç»„åˆ")
print(f"æ€»ç”¨æ—¶: {(time.time() - start_time)/60:.1f} åˆ†é’Ÿ")

# --------- åˆ†æç»“æœ ---------
print(f"\nğŸŒŸ å…¨å±€æœ€ä½³ç»“æœ:")
print(f"ç»„åˆID: {best_global_performance['Combination_ID']}")
print(f"ç‰¹å¾æ€»æ•°: {best_global_performance['Total_Features']}")
print(f"å€™é€‰ç‰¹å¾æ•°: {best_global_performance['Selected_Candidates']}")
print(f"RMSE: {best_global_performance['RMSE_Mean']:.4f} Â± {best_global_performance['RMSE_Std']:.4f}")
print(f"RÂ²: {best_global_performance['R2_Mean']:.4f} Â± {best_global_performance['R2_Std']:.4f}")
print(f"é€‰ä¸­çš„å€™é€‰ç‰¹å¾: {best_global_performance['Selected_Candidate_Names']}")
print(f"å®Œæ•´ç‰¹å¾é›†: {best_global_performance['All_Features']}")

# --------- ä¿å­˜ç»“æœ ---------
results_df = pd.DataFrame(all_results)

# æŒ‰RMSEæ’åº
results_df_sorted = results_df.sort_values('RMSE_Mean').reset_index(drop=True)

# ä¿å­˜è¯¦ç»†ç»“æœ
output_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦ç©·ä¸¾æ¶ˆé™¤ç»“æœ.xlsx'
results_df_sorted.to_excel(output_file, index=False)

# ä¿å­˜æœ€ä½³ç»“æœåˆ†æ
top_results = results_df_sorted.head(20)  # å‰20ä¸ªæœ€ä½³ç»“æœ
top_results_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦ç©·ä¸¾æ¶ˆé™¤å‰20æœ€ä½³.xlsx'
top_results.to_excel(top_results_file, index=False)

# ä¿å­˜æœ€ä½³ç‰¹å¾å­é›†è¯¦ç»†ä¿¡æ¯
best_subset_info = pd.DataFrame({
    'Metric': ['Combination_ID', 'Total_Features', 'Selected_Candidates', 'RMSE_Mean', 'RMSE_Std', 'R2_Mean', 'R2_Std'],
    'Value': [
        best_global_performance['Combination_ID'],
        best_global_performance['Total_Features'],
        best_global_performance['Selected_Candidates'],
        best_global_performance['RMSE_Mean'],
        best_global_performance['RMSE_Std'],
        best_global_performance['R2_Mean'],
        best_global_performance['R2_Std']
    ]
})

best_features_list = pd.DataFrame({
    'Feature_Type': ['Fixed'] * len(fixed_features) + ['Selected'] * len(best_global_performance['Selected_Candidate_Names']),
    'Feature_Name': fixed_features + best_global_performance['Selected_Candidate_Names']
})

# ä¿å­˜æœ€ä½³ç‰¹å¾ç»„åˆ
best_combination_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦ç©·ä¸¾æ¶ˆé™¤æœ€ä½³ç»„åˆ.xlsx'
with pd.ExcelWriter(best_combination_file, engine='openpyxl') as writer:
    best_subset_info.to_excel(writer, sheet_name='Performance_Info', index=False)
    best_features_list.to_excel(writer, sheet_name='Feature_List', index=False)

print(f"\nğŸ“ ç»“æœå·²ä¿å­˜:")
print(f"  å®Œæ•´ç»“æœ: {output_file}")
print(f"  å‰20æœ€ä½³ç»“æœ: {top_results_file}")
print(f"  æœ€ä½³ç‰¹å¾ç»„åˆ: {best_combination_file}")

# --------- ç»“æœåˆ†æå’Œå¯è§†åŒ– ---------
print(f"\nğŸ“Š ç»“æœç»Ÿè®¡åˆ†æ:")
print(f"å¹³å‡RMSE: {results_df['RMSE_Mean'].mean():.4f}")
print(f"æœ€ä½³RMSE: {results_df['RMSE_Mean'].min():.4f}")
print(f"æœ€å·®RMSE: {results_df['RMSE_Mean'].max():.4f}")
print(f"RMSEæ ‡å‡†å·®: {results_df['RMSE_Mean'].std():.4f}")

# æŒ‰ç‰¹å¾æ•°é‡åˆ†ç»„åˆ†æ
feature_count_analysis = results_df.groupby('Total_Features').agg({
    'RMSE_Mean': ['count', 'mean', 'min', 'max', 'std'],
    'R2_Mean': ['mean', 'min', 'max']
}).round(4)

print(f"\nğŸ“ˆ æŒ‰ç‰¹å¾æ•°é‡çš„æ€§èƒ½åˆ†æ:")
print(feature_count_analysis)

# æ‰¾å‡ºæ¯ä¸ªç‰¹å¾æ•°é‡ä¸‹çš„æœ€ä½³ç»“æœ
best_by_feature_count = results_df.loc[results_df.groupby('Total_Features')['RMSE_Mean'].idxmin()]
print(f"\nğŸ† æ¯ä¸ªç‰¹å¾æ•°é‡ä¸‹çš„æœ€ä½³ç»“æœ:")
for _, row in best_by_feature_count.iterrows():
    print(f"  {row['Total_Features']}ä¸ªç‰¹å¾: RMSE={row['RMSE_Mean']:.4f}Â±{row['RMSE_Std']:.4f}, RÂ²={row['R2_Mean']:.4f}Â±{row['R2_Std']:.4f}")

# ç»˜åˆ¶ç‰¹å¾æ•°é‡vsæ€§èƒ½çš„å…³ç³»å›¾
plt.figure(figsize=(12, 8))

# å­å›¾1: RMSE vs ç‰¹å¾æ•°é‡
plt.subplot(2, 2, 1)
feature_counts = results_df['Total_Features'].values
rmse_values = results_df['RMSE_Mean'].values
plt.scatter(feature_counts, rmse_values, alpha=0.6, s=20)
plt.plot(best_by_feature_count['Total_Features'], best_by_feature_count['RMSE_Mean'], 'r-o', label='Best per feature count')
plt.xlabel('Number of Features')
plt.ylabel('RMSE')
plt.title('RMSE vs Number of Features')
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾2: RÂ² vs ç‰¹å¾æ•°é‡
plt.subplot(2, 2, 2)
r2_values = results_df['R2_Mean'].values
plt.scatter(feature_counts, r2_values, alpha=0.6, s=20)
plt.plot(best_by_feature_count['Total_Features'], best_by_feature_count['R2_Mean'], 'r-o', label='Best per feature count')
plt.xlabel('Number of Features')
plt.ylabel('RÂ²')
plt.title('RÂ² vs Number of Features')
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾3: RMSEåˆ†å¸ƒç›´æ–¹å›¾
plt.subplot(2, 2, 3)
plt.hist(rmse_values, bins=30, alpha=0.7, edgecolor='black')
plt.axvline(best_global_performance['RMSE_Mean'], color='red', linestyle='--', label=f'Best: {best_global_performance["RMSE_Mean"]:.4f}')
plt.xlabel('RMSE')
plt.ylabel('Frequency')
plt.title('RMSE Distribution')
plt.legend()
plt.grid(True, alpha=0.3)

# å­å›¾4: å‰20æœ€ä½³ç»“æœ
plt.subplot(2, 2, 4)
top_20 = results_df_sorted.head(20)
plt.bar(range(len(top_20)), top_20['RMSE_Mean'], alpha=0.7)
plt.xlabel('Rank')
plt.ylabel('RMSE')
plt.title('Top 20 Best Results')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# æœ€ç»ˆéªŒè¯æœ€ä½³ç‰¹å¾ç»„åˆ
print(f"\nğŸ” æœ€ä½³ç‰¹å¾ç»„åˆçš„ç‹¬ç«‹éªŒè¯:")
X_best = X_scaled[best_global_feature_set]
final_rmse, final_rmse_std, final_r2, final_r2_std = evaluate_model_with_ten_fold_cv(X_best, y)
print(f"éªŒè¯ç»“æœ: RMSE={final_rmse:.4f} Â± {final_rmse_std:.4f}, RÂ²={final_r2:.4f} Â± {final_r2_std:.4f}")

# ç»˜åˆ¶æœ€ä½³ç‰¹å¾ç»„åˆçš„é¢„æµ‹ç»“æœ
print(f"ç”Ÿæˆæœ€ä½³ç‰¹å¾ç»„åˆçš„é¢„æµ‹å¯è§†åŒ–...")
all_y_true = []
all_y_pred = []

for seed in range(40, 50):
    fold_indices = custom_group_kfold(X_best, y, group_labels, n_splits=5, random_state=seed)

    for fold, test_idx in fold_indices.items():
        train_idx = np.setdiff1d(np.arange(len(X_best)), test_idx)
        X_train, X_test = X_best.iloc[train_idx], X_best.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

        model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        all_y_true.extend(y_test.tolist())
        all_y_pred.extend(y_pred.tolist())

plt.figure(figsize=(10, 8))
plt.scatter(all_y_true, all_y_pred, color='gold', alpha=0.6, label='Best Feature Combination')
plt.plot([min(all_y_true), max(all_y_true)], [min(all_y_true), max(all_y_true)],
         color='red', linestyle='--', label='Perfect Prediction')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f"Best Feature Combination Performance (Exhaustive Search)\n" +
          f"Features: {len(best_global_feature_set)}, RMSE={final_rmse:.4f}Â±{final_rmse_std:.4f}, RÂ²={final_r2:.4f}Â±{final_r2_std:.4f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print(f"\nâœ… ç©·ä¸¾æ¶ˆé™¤ç‰¹å¾é€‰æ‹©å®Œæˆï¼")
