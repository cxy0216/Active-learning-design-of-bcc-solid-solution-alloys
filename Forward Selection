import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold

file_path = r'/content/yield_strength_pcc.xlsx'
data = pd.read_excel(file_path)

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

best_C = 900.81
best_epsilon = 3.8196

def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}
    for group in unique_groups:
        group_samples = groups[group]
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

def evaluate_model_with_ten_fold_cv(X, y):
    all_rmse_results = []
    all_r2_results = []
    all_y_true = []
    all_y_pred = []
    for seed in range(40, 50):
        fold_indices = custom_group_kfold(X, y, group_labels, n_splits=5, random_state=seed)
        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X)), test_idx)
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            all_rmse_results.append(rmse)
            all_r2_results.append(r2)
            all_y_true.extend(y_test.tolist())
            all_y_pred.extend(y_pred.tolist())
    mean_rmse = np.mean(all_rmse_results)
    std_rmse = np.std(all_rmse_results)
    mean_r2 = np.mean(all_r2_results)
    std_r2 = np.std(all_r2_results)
    return mean_rmse, std_rmse, mean_r2, std_r2, all_y_true, all_y_pred

selected_features = list(X_scaled.columns[:13])
candidate_features = list(X_scaled.columns[13:])

all_results = []
best_features_to_add = []
rmse_values = []
r2_values = []
rmse_std_values = []
r2_std_values = []

global_best_rmse = float('inf')
global_best_feature_set = None
global_best_performance = None
feature_sets_performance = []

X_current = X_scaled[selected_features]
initial_rmse, initial_rmse_std, initial_r2, initial_r2_std, _, _ = evaluate_model_with_ten_fold_cv(X_current, y)

feature_sets_performance.append({
    'Round': 0,
    'Feature_Count': len(selected_features),
    'Features': selected_features.copy(),
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
})

global_best_rmse = initial_rmse
global_best_feature_set = selected_features.copy()
global_best_performance = {
    'Round': 0,
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
}

max_features = len(X_scaled.columns)

round_num = 1
while len(candidate_features) > 0 and len(selected_features) < max_features:
    best_rmse = float('inf')
    best_r2 = -np.inf
    best_feature = None
    best_rmse_std = 0
    best_r2_std = 0
    best_y_true = []
    best_y_pred = []

    for i, feature in enumerate(candidate_features):
        test_features = selected_features + [feature]
        X_test = X_scaled[test_features]
        rmse, rmse_std, r2, r2_std, y_true, y_pred = evaluate_model_with_ten_fold_cv(X_test, y)

        if rmse < best_rmse:
            best_rmse = rmse
            best_rmse_std = rmse_std
            best_r2 = r2
            best_r2_std = r2_std
            best_feature = feature
            best_y_true = y_true
            best_y_pred = y_pred

        all_results.append({
            'Round': round_num,
            'Added Feature': feature,
            'RMSE_Mean': rmse,
            'RMSE_Std': rmse_std,
            'R2_Mean': r2,
            'R2_Std': r2_std,
            'Current Features Count': len(selected_features) + 1
        })

    selected_features.append(best_feature)
    candidate_features.remove(best_feature)

    best_features_to_add.append(best_feature)
    rmse_values.append(best_rmse)
    r2_values.append(best_r2)
    rmse_std_values.append(best_rmse_std)
    r2_std_values.append(best_r2_std)

    feature_sets_performance.append({
        'Round': round_num,
        'Feature_Count': len(selected_features),
        'Features': selected_features.copy(),
        'RMSE_Mean': best_rmse,
        'RMSE_Std': best_rmse_std,
        'R2_Mean': best_r2,
        'R2_Std': best_r2_std
    })

    if best_rmse < global_best_rmse:
        global_best_rmse = best_rmse
        global_best_feature_set = selected_features.copy()
        global_best_performance = {
            'Round': round_num,
            'RMSE_Mean': best_rmse,
            'RMSE_Std': best_rmse_std,
            'R2_Mean': best_r2,
            'R2_Std': best_r2_std,
            'Added_Feature': best_feature
        }

    plt.figure(figsize=(8, 6))
    plt.scatter(best_y_true, best_y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Round {round_num}: After Adding '{best_feature}'\n" +
              f"RMSE={best_rmse:.4f} ± {best_rmse_std:.4f}, R²={best_r2:.4f} ± {best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    round_num += 1

all_results_df = pd.DataFrame(all_results)
output_file = '/content/drive/MyDrive/HEA_data/forward_selection_results.xlsx'
all_results_df.to_excel(output_file, index=False)

if best_features_to_add:
    best_features_df = pd.DataFrame({
        'Round': range(1, len(best_features_to_add) + 1),
        'Best Feature to Add': best_features_to_add,
        'Best RMSE Mean': rmse_values,
        'Best RMSE Std': rmse_std_values,
        'Best R² Mean': r2_values,
        'Best R² Std': r2_std_values,
        'Total Features': [13 + i + 1 for i in range(len(best_features_to_add))]
    })
    best_features_file = '/content/drive/MyDrive/HEA_data/forward_best_features.xlsx'
    best_features_df.to_excel(best_features_file, index=False)

feature_sets_df = pd.DataFrame(feature_sets_performance)
feature_sets_file = '/content/drive/MyDrive/HEA_data/forward_feature_sets.xlsx'
feature_sets_df.to_excel(feature_sets_file, index=False)

best_subset_info = pd.DataFrame({
    'Metric': ['Round', 'Feature_Count', 'RMSE_Mean', 'RMSE_Std', 'R2_Mean', 'R2_Std'],
    'Value': [
        global_best_performance['Round'],
        len(global_best_feature_set),
        global_best_performance['RMSE_Mean'],
        global_best_performance['RMSE_Std'],
        global_best_performance['R2_Mean'],
        global_best_performance['R2_Std']
    ]
})

best_features_list = pd.DataFrame({
    'Feature_Index': range(len(global_best_feature_set)),
    'Feature_Name': global_best_feature_set
})

best_subset_file = '/content/drive/MyDrive/HEA_data/forward_best_subset.xlsx'
with pd.ExcelWriter(best_subset_file, engine='openpyxl') as writer:
    best_subset_info.to_excel(writer, sheet_name='Performance_Info', index=False)
    best_features_list.to_excel(writer, sheet_name='Feature_List', index=False)

X_final = X_scaled[selected_features]
final_rmse, final_rmse_std, final_r2, final_r2_std, final_y_true, final_y_pred = evaluate_model_with_ten_fold_cv(X_final, y)

plt.figure(figsize=(10, 8))
plt.scatter(final_y_true, final_y_pred, color='green', alpha=0.6, label='Final Model')
plt.plot([min(final_y_true), max(final_y_true)], [min(final_y_true), max(final_y_true)],
         color='red', linestyle='--', label='Perfect Prediction')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f"Final Model Performance (Forward Selection)\n" +
          f"Features: {len(selected_features)}, RMSE={final_rmse:.4f}±{final_rmse_std:.4f}, R²={final_r2:.4f}±{final_r2_std:.4f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

if global_best_performance['Round'] != len(feature_sets_performance) - 1:
    X_best_subset = X_scaled[global_best_feature_set]
    best_rmse, best_rmse_std, best_r2, best_r2_std, best_y_true, best_y_pred = evaluate_model_with_ten_fold_cv(X_best_subset, y)

    plt.figure(figsize=(10, 8))
    plt.scatter(best_y_true, best_y_pred, color='gold', alpha=0.6, label='Best Feature Subset')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Best Feature Subset Performance (Round {global_best_performance['Round']})\n" +
              f"Features: {len(global_best_feature_set)}, RMSE={best_rmse:.4f}±{best_rmse_std:.4f}, R²={best_r2:.4f}±{best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
