import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold

# --------- è¯»å–æ•°æ® ---------
file_path = r'/content/å±ˆæœå¼ºåº¦ç‰¹å¾PCCç­›é€‰.xlsx'
data = pd.read_excel(file_path)

# --------- ç‰¹å¾ & ç›®æ ‡ ---------
X = data.iloc[:, :-1]  # ç‰¹å¾åˆ—
y = data.iloc[:, -1]   # ç›®æ ‡å˜é‡

# --------- æ•°æ®å½’ä¸€åŒ– ---------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

# è·å–æœ€ä½³è¶…å‚æ•°
best_C = 900.81
best_epsilon = 3.8196
print(f"Initial Best Parameters: C = {best_C}, epsilon = {best_epsilon}")

# --------- è‡ªå®šä¹‰åˆ†ç»„å‡½æ•° ---------
def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    """ æŒ‰ç»„å‡åŒ€åˆ†é…æ ·æœ¬åˆ°æ¯ä¸ªæŠ˜å ä¸­ """
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}

    # åˆ›å»º KFold
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}

    # æŒ‰ç…§æŠ˜å è¿›è¡Œåˆ†é…
    for group in unique_groups:
        group_samples = groups[group]
        # åœ¨æ¯ä¸ªæŠ˜å ä¸­å‡åŒ€åˆ†é…è¯¥ç»„çš„æ ·æœ¬
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])

    # ç¡®ä¿æ¯ä¸ªæŠ˜å çš„æ ·æœ¬åˆ†å¸ƒå‡åŒ€
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

# Define group labels
group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

# --------- åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°å‡½æ•° ---------
def evaluate_model_with_ten_fold_cv(X, y):
    """ä½¿ç”¨åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    all_rmse_results = []
    all_r2_results = []
    all_y_true = []
    all_y_pred = []

    for seed in range(40, 50):  # seeds 40-49
        fold_indices = custom_group_kfold(X, y, group_labels, n_splits=5, random_state=seed)

        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X)), test_idx)
            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

            # è®­ç»ƒæ¨¡å‹
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)

            all_rmse_results.append(rmse)
            all_r2_results.append(r2)
            all_y_true.extend(y_test.tolist())
            all_y_pred.extend(y_pred.tolist())

    # è¿”å›50ä¸ªç»“æœçš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥åŠç”¨äºç»˜å›¾çš„é¢„æµ‹å€¼
    mean_rmse = np.mean(all_rmse_results)
    std_rmse = np.std(all_rmse_results)
    mean_r2 = np.mean(all_r2_results)
    std_r2 = np.std(all_r2_results)

    return mean_rmse, std_rmse, mean_r2, std_r2, all_y_true, all_y_pred

# --------- å‰å‘ç‰¹å¾é€‰æ‹© ---------
# åˆå§‹åŒ–ï¼šåªåŒ…å«å‰13ä¸ªå›ºå®šç‰¹å¾
selected_features = list(X_scaled.columns[:13])
candidate_features = list(X_scaled.columns[13:])

print(f"å¼€å§‹å‰å‘ç‰¹å¾é€‰æ‹©è¿‡ç¨‹")
print(f"å›ºå®šç‰¹å¾æ•°: {len(selected_features)}")
print(f"å€™é€‰ç‰¹å¾æ•°: {len(candidate_features)}")
print(f"å›ºå®šç‰¹å¾: {selected_features}")
print(f"å€™é€‰ç‰¹å¾: {candidate_features}")

# ç”¨äºä¿å­˜æ¯è½®æ·»åŠ ç‰¹å¾åçš„æ‰€æœ‰ç»“æœ
all_results = []
# ç”¨äºè®°å½•æ¯è½®æ·»åŠ çš„æœ€ä½³ç‰¹å¾åŠå…¶å¯¹åº”çš„æ€§èƒ½
best_features_to_add = []
rmse_values = []
r2_values = []
rmse_std_values = []
r2_std_values = []

# è®°å½•å…¨å±€æœ€ä½³æ€§èƒ½å’Œå¯¹åº”çš„ç‰¹å¾å­é›†
global_best_rmse = float('inf')
global_best_feature_set = None
global_best_performance = None
feature_sets_performance = []  # è®°å½•æ¯è½®åçš„ç‰¹å¾é›†å’Œæ€§èƒ½

# è¯„ä¼°åˆå§‹ç‰¹å¾é›†æ€§èƒ½ï¼ˆåªæœ‰å‰13ä¸ªç‰¹å¾ï¼‰
print(f"\n=== åˆå§‹ç‰¹å¾é›†è¯„ä¼°ï¼ˆå‰13ä¸ªç‰¹å¾ï¼‰===")
X_current = X_scaled[selected_features]
initial_rmse, initial_rmse_std, initial_r2, initial_r2_std, _, _ = evaluate_model_with_ten_fold_cv(X_current, y)
print(f"åˆå§‹æ€§èƒ½: RMSE={initial_rmse:.4f} Â± {initial_rmse_std:.4f}, RÂ²={initial_r2:.4f} Â± {initial_r2_std:.4f}")

# è®°å½•åˆå§‹ç‰¹å¾é›†
feature_sets_performance.append({
    'Round': 0,
    'Feature_Count': len(selected_features),
    'Features': selected_features.copy(),
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
})

global_best_rmse = initial_rmse
global_best_feature_set = selected_features.copy()
global_best_performance = {
    'Round': 0,
    'RMSE_Mean': initial_rmse,
    'RMSE_Std': initial_rmse_std,
    'R2_Mean': initial_r2,
    'R2_Std': initial_r2_std
}

# è®¾ç½®åœæ­¢æ¡ä»¶
max_features = len(X_scaled.columns)  # æœ€å¤šæ·»åŠ åˆ°æ‰€æœ‰ç‰¹å¾

round_num = 1
while len(candidate_features) > 0 and len(selected_features) < max_features:
    print(f"\n=== ç¬¬ {round_num} è½®ç‰¹å¾æ·»åŠ  ===")
    print(f"å½“å‰ç‰¹å¾æ•°: {len(selected_features)}")
    print(f"å€™é€‰ç‰¹å¾æ•°: {len(candidate_features)}")

    best_rmse = float('inf')
    best_r2 = -np.inf
    best_feature = None
    best_rmse_std = 0
    best_r2_std = 0
    best_y_true = []
    best_y_pred = []

    print(f"å€™é€‰ç‰¹å¾: {candidate_features}")

    # å°è¯•æ·»åŠ æ¯ä¸ªå€™é€‰ç‰¹å¾
    for i, feature in enumerate(candidate_features):
        print(f"  æ­£åœ¨è¯„ä¼°æ·»åŠ ç‰¹å¾ '{feature}' ({i+1}/{len(candidate_features)})...")

        # åˆ›å»ºåŒ…å«æ–°ç‰¹å¾çš„ç‰¹å¾é›†
        test_features = selected_features + [feature]
        X_test = X_scaled[test_features]

        # ä½¿ç”¨åæ¬¡äº”æŠ˜äº¤å‰éªŒè¯è®¡ç®— RMSE å’Œ RÂ²
        rmse, rmse_std, r2, r2_std, y_true, y_pred = evaluate_model_with_ten_fold_cv(X_test, y)

        # æ‰“å°å½“å‰æ·»åŠ ç‰¹å¾åçš„ç»“æœ
        print(f"    æ·»åŠ  '{feature}' - RMSE: {rmse:.4f} Â± {rmse_std:.4f}, RÂ²: {r2:.4f} Â± {r2_std:.4f}")

        # æ›´æ–°æœ€ä½³ç»“æœï¼ˆåŸºäºRMSEå‡å€¼ï¼‰
        if rmse < best_rmse:
            best_rmse = rmse
            best_rmse_std = rmse_std
            best_r2 = r2
            best_r2_std = r2_std
            best_feature = feature
            best_y_true = y_true
            best_y_pred = y_pred

        # ä¿å­˜å½“å‰æ·»åŠ ç‰¹å¾çš„æ•ˆæœ
        all_results.append({
            'Round': round_num,
            'Added Feature': feature,
            'RMSE_Mean': rmse,
            'RMSE_Std': rmse_std,
            'R2_Mean': r2,
            'R2_Std': r2_std,
            'Current Features Count': len(selected_features) + 1
        })

    # è¾“å‡ºæœ€ä½³ç‰¹å¾å’Œå¯¹åº”çš„ RMSE å’Œ RÂ²
    print(f"\n  âœ… æœ€ä½³æ·»åŠ ç‰¹å¾: {best_feature}")
    print(f"  ğŸ“Š æœ€ä½³æ€§èƒ½: RMSE={best_rmse:.4f} Â± {best_rmse_std:.4f}, RÂ²={best_r2:.4f} Â± {best_r2_std:.4f}")

    # è®¡ç®—æ€§èƒ½æ”¹å–„
    current_best_rmse = feature_sets_performance[-1]['RMSE_Mean']
    improvement = current_best_rmse - best_rmse
    print(f"  ğŸ“ˆ æ€§èƒ½æ”¹å–„: RMSEå‡å°‘ {improvement:.4f}")

    # æ·»åŠ æœ€ä½³ç‰¹å¾åˆ°é€‰ä¸­åˆ—è¡¨
    selected_features.append(best_feature)
    candidate_features.remove(best_feature)

    # è®°å½•æœ€ä½³ç‰¹å¾å’Œæ€§èƒ½
    best_features_to_add.append(best_feature)
    rmse_values.append(best_rmse)
    r2_values.append(best_r2)
    rmse_std_values.append(best_rmse_std)
    r2_std_values.append(best_r2_std)

    # è®°å½•å½“å‰ç‰¹å¾é›†å’Œæ€§èƒ½
    feature_sets_performance.append({
        'Round': round_num,
        'Feature_Count': len(selected_features),
        'Features': selected_features.copy(),
        'RMSE_Mean': best_rmse,
        'RMSE_Std': best_rmse_std,
        'R2_Mean': best_r2,
        'R2_Std': best_r2_std
    })

    # æ›´æ–°å…¨å±€æœ€ä½³æ€§èƒ½
    if best_rmse < global_best_rmse:
        global_best_rmse = best_rmse
        global_best_feature_set = selected_features.copy()
        global_best_performance = {
            'Round': round_num,
            'RMSE_Mean': best_rmse,
            'RMSE_Std': best_rmse_std,
            'R2_Mean': best_r2,
            'R2_Std': best_r2_std,
            'Added_Feature': best_feature
        }
        print(f"  ğŸŒŸ å‘ç°æ–°çš„å…¨å±€æœ€ä½³æ€§èƒ½ï¼")

    # ç»˜åˆ¶å®é™…å€¼ä¸é¢„æµ‹å€¼çš„å¯¹æ¯”å›¾
    plt.figure(figsize=(8, 6))
    plt.scatter(best_y_true, best_y_pred, color='blue', alpha=0.6, label='Predicted vs Actual')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Round {round_num}: After Adding '{best_feature}'\n" +
              f"RMSE={best_rmse:.4f} Â± {best_rmse_std:.4f}, RÂ²={best_r2:.4f} Â± {best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

    round_num += 1

print(f"\nğŸ‰ å‰å‘ç‰¹å¾é€‰æ‹©å®Œæˆï¼")
print(f"æœ€ç»ˆé€‰æ‹©ç‰¹å¾æ•°: {len(selected_features)}")
print(f"æœ€ç»ˆé€‰æ‹©çš„ç‰¹å¾: {selected_features}")

# æ˜¾ç¤ºå…¨å±€æœ€ä½³æ€§èƒ½
print(f"\nğŸŒŸ å…¨å±€æœ€ä½³æ€§èƒ½:")
print(f"è½®æ¬¡: {global_best_performance['Round']}")
print(f"ç‰¹å¾æ•°: {len(global_best_feature_set)}")
print(f"RMSE: {global_best_performance['RMSE_Mean']:.4f} Â± {global_best_performance['RMSE_Std']:.4f}")
print(f"RÂ²: {global_best_performance['R2_Mean']:.4f} Â± {global_best_performance['R2_Std']:.4f}")
print(f"æœ€ä½³ç‰¹å¾é›†: {global_best_feature_set}")

# å°†ç»“æœä¿å­˜åˆ° DataFrame ä¸­
all_results_df = pd.DataFrame(all_results)

# ä¿å­˜è¯¦ç»†ç»“æœ
output_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦å‰å‘é€‰æ‹©ç»“æœ.xlsx'
all_results_df.to_excel(output_file, index=False)

# ä¿å­˜æœ€ä½³æ·»åŠ ç‰¹å¾
if best_features_to_add:  # å¦‚æœæœ‰æ·»åŠ çš„ç‰¹å¾
    best_features_df = pd.DataFrame({
        'Round': range(1, len(best_features_to_add) + 1),
        'Best Feature to Add': best_features_to_add,
        'Best RMSE Mean': rmse_values,
        'Best RMSE Std': rmse_std_values,
        'Best RÂ² Mean': r2_values,
        'Best RÂ² Std': r2_std_values,
        'Total Features': [13 + i + 1 for i in range(len(best_features_to_add))]
    })

    best_features_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦å‰å‘é€‰æ‹©æœ€ä½³ç‰¹å¾.xlsx'
    best_features_df.to_excel(best_features_file, index=False)

# ä¿å­˜æ¯è½®ç‰¹å¾é›†æ€§èƒ½å¯¹æ¯”
feature_sets_df = pd.DataFrame(feature_sets_performance)
feature_sets_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦å‰å‘é€‰æ‹©ç‰¹å¾é›†æ€§èƒ½.xlsx'
feature_sets_df.to_excel(feature_sets_file, index=False)

# ä¿å­˜å…¨å±€æœ€ä½³ç‰¹å¾å­é›†
best_subset_info = pd.DataFrame({
    'Metric': ['Round', 'Feature_Count', 'RMSE_Mean', 'RMSE_Std', 'R2_Mean', 'R2_Std'],
    'Value': [
        global_best_performance['Round'],
        len(global_best_feature_set),
        global_best_performance['RMSE_Mean'],
        global_best_performance['RMSE_Std'],
        global_best_performance['R2_Mean'],
        global_best_performance['R2_Std']
    ]
})

best_features_list = pd.DataFrame({
    'Feature_Index': range(len(global_best_feature_set)),
    'Feature_Name': global_best_feature_set
})

# ä¿å­˜æœ€ä½³ç‰¹å¾å­é›†
best_subset_file = '/content/drive/MyDrive/é«˜ç†µåˆé‡‘æ•°æ®/å±ˆæœå¼ºåº¦å‰å‘é€‰æ‹©æœ€ä½³ç‰¹å¾å­é›†.xlsx'
with pd.ExcelWriter(best_subset_file, engine='openpyxl') as writer:
    best_subset_info.to_excel(writer, sheet_name='Performance_Info', index=False)
    best_features_list.to_excel(writer, sheet_name='Feature_List', index=False)

print(f"\nğŸ“ ç»“æœå·²ä¿å­˜:")
print(f"  è¯¦ç»†ç»“æœ: {output_file}")
if best_features_to_add:
    print(f"  æœ€ä½³æ·»åŠ ç‰¹å¾: {best_features_file}")
print(f"  ç‰¹å¾é›†æ€§èƒ½å¯¹æ¯”: {feature_sets_file}")
print(f"  æœ€ä½³ç‰¹å¾å­é›†: {best_subset_file}")

# æ˜¾ç¤ºç‰¹å¾æ·»åŠ é¡ºåºæ‘˜è¦
if best_features_to_add:
    print(f"\nğŸ“‹ ç‰¹å¾æ·»åŠ é¡ºåºæ‘˜è¦:")
    for i, (feature, rmse, rmse_std, r2, r2_std) in enumerate(zip(
        best_features_to_add, rmse_values, rmse_std_values, r2_values, r2_std_values)):
        print(f"  ç¬¬{i+1}è½®: æ·»åŠ  '{feature}' -> RMSE={rmse:.4f}Â±{rmse_std:.4f}, RÂ²={r2:.4f}Â±{r2_std:.4f}")

# æ˜¾ç¤ºæ¯è½®æ€§èƒ½å˜åŒ–
print(f"\nğŸ“Š æ¯è½®æ€§èƒ½å˜åŒ–:")
for perf in feature_sets_performance:
    status = "ğŸŒŸ æœ€ä½³" if perf['Round'] == global_best_performance['Round'] else ""
    print(f"  è½®æ¬¡{perf['Round']:2d}: {perf['Feature_Count']:2d}ä¸ªç‰¹å¾ -> RMSE={perf['RMSE_Mean']:.4f}Â±{perf['RMSE_Std']:.4f}, RÂ²={perf['R2_Mean']:.4f}Â±{perf['R2_Std']:.4f} {status}")

# æœ€ç»ˆæ¨¡å‹æ€§èƒ½è¯„ä¼°
print(f"\nğŸ” æœ€ç»ˆæ¨¡å‹æ€§èƒ½è¯„ä¼°...")
X_final = X_scaled[selected_features]
final_rmse, final_rmse_std, final_r2, final_r2_std, final_y_true, final_y_pred = evaluate_model_with_ten_fold_cv(X_final, y)
print(f"æœ€ç»ˆæ¨¡å‹ - 10x5-Fold CV RMSE = {final_rmse:.4f} Â± {final_rmse_std:.4f}")
print(f"æœ€ç»ˆæ¨¡å‹ - 10x5-Fold CV RÂ² = {final_r2:.4f} Â± {final_r2_std:.4f}")

# ç»˜åˆ¶æœ€ç»ˆæ¨¡å‹çš„é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 8))
plt.scatter(final_y_true, final_y_pred, color='green', alpha=0.6, label='Final Model')
plt.plot([min(final_y_true), max(final_y_true)], [min(final_y_true), max(final_y_true)],
         color='red', linestyle='--', label='Perfect Prediction')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title(f"Final Model Performance (Forward Selection)\n" +
          f"Features: {len(selected_features)}, RMSE={final_rmse:.4f}Â±{final_rmse_std:.4f}, RÂ²={final_r2:.4f}Â±{final_r2_std:.4f}")
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# ç»˜åˆ¶å…¨å±€æœ€ä½³ç‰¹å¾å­é›†çš„æ€§èƒ½ï¼ˆå¦‚æœä¸æ˜¯æœ€ç»ˆæ¨¡å‹ï¼‰
if global_best_performance['Round'] != len(feature_sets_performance) - 1:
    print(f"\nğŸ¯ ä½¿ç”¨å…¨å±€æœ€ä½³ç‰¹å¾å­é›†è¿›è¡Œç‹¬ç«‹è¯„ä¼°...")
    X_best_subset = X_scaled[global_best_feature_set]

    # è¯„ä¼°æ€§èƒ½
    best_rmse, best_rmse_std, best_r2, best_r2_std, best_y_true, best_y_pred = evaluate_model_with_ten_fold_cv(X_best_subset, y)

    print(f"æœ€ä½³ç‰¹å¾å­é›†ç‹¬ç«‹è¯„ä¼°:")
    print(f"RMSE = {best_rmse:.4f} Â± {best_rmse_std:.4f}")
    print(f"RÂ² = {best_r2:.4f} Â± {best_r2_std:.4f}")

    # ç»˜åˆ¶æœ€ä½³ç‰¹å¾å­é›†çš„é¢„æµ‹ç»“æœ
    plt.figure(figsize=(10, 8))
    plt.scatter(best_y_true, best_y_pred, color='gold', alpha=0.6, label='Best Feature Subset')
    plt.plot([min(best_y_true), max(best_y_true)], [min(best_y_true), max(best_y_true)],
             color='red', linestyle='--', label='Perfect Prediction')
    plt.xlabel('Actual Values')
    plt.ylabel('Predicted Values')
    plt.title(f"Best Feature Subset Performance (Round {global_best_performance['Round']})\n" +
              f"Features: {len(global_best_feature_set)}, RMSE={best_rmse:.4f}Â±{best_rmse_std:.4f}, RÂ²={best_r2:.4f}Â±{best_r2_std:.4f}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
