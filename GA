!pip install deap
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold, cross_val_predict
from bayes_opt import BayesianOptimization
from deap import base, creator, tools, algorithms

file_path = r'/content/yield_strength_pcc.xlsx'
data = pd.read_excel(file_path)

X = data.iloc[:, :-1]
y = data.iloc[:, -1]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

best_C = 900.81
best_epsilon = 3.8196

def custom_group_kfold(X, y, group_labels, n_splits=5, random_state=42):
    unique_groups = np.unique(group_labels)
    groups = {group: np.where(group_labels == group)[0] for group in unique_groups}
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
    fold_indices = {i: [] for i in range(n_splits)}
    for group in unique_groups:
        group_samples = groups[group]
        for fold, (train_idx, test_idx) in enumerate(kf.split(group_samples)):
            fold_indices[fold].extend(group_samples[test_idx])
    for fold in fold_indices:
        fold_indices[fold] = np.array(fold_indices[fold])
    return fold_indices

group_sizes = [15,6,12,5,11,11,7,5,9,5,7,11,7]
group_labels = []
current_group = 1
for size in group_sizes:
    group_labels.extend([current_group] * size)
    current_group += 1
group_labels = np.array(group_labels)

creator.create("FitnessMinMax", base.Fitness, weights=(-1.0, 1.0))
creator.create("Individual", list, fitness=creator.FitnessMinMax)

def create_individual():
    individual = [1] * 13
    individual.extend([np.random.randint(0, 2) for _ in range(len(X_scaled.columns) - 13)])
    return individual

def evaluate(individual):
    selected_features = [X_scaled.columns[i] for i in range(13) if individual[i] == 1]
    selected_features += [X_scaled.columns[i] for i in range(13, len(individual)) if individual[i] == 1]
    
    if len(selected_features) == 0:
        return 999999, 0.0
    
    X_selected = X_scaled[selected_features]
    all_rmse_results = []
    all_r2_results = []
    
    for seed in range(40, 50):
        fold_indices = custom_group_kfold(X_selected, y, group_labels, n_splits=5, random_state=seed)
        for fold, test_idx in fold_indices.items():
            train_idx = np.setdiff1d(np.arange(len(X_selected)), test_idx)
            X_train, X_test = X_selected.iloc[train_idx], X_selected.iloc[test_idx]
            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
            model = SVR(C=best_C, epsilon=best_epsilon, kernel='rbf')
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            r2 = r2_score(y_test, y_pred)
            all_rmse_results.append(rmse)
            all_r2_results.append(r2)
    
    avg_rmse = np.mean(all_rmse_results)
    avg_r2 = np.mean(all_r2_results)
    return avg_rmse, avg_r2

def mutate(individual):
    for i in range(13, len(individual)):
        if np.random.rand() < 0.1:
            individual[i] = 1 - individual[i]
    return individual,

def get_additional_features(individual):
    additional_features = []
    for i in range(13, len(individual)):
        if individual[i] == 1:
            additional_features.append(X_scaled.columns[i])
    return additional_features

toolbox = base.Toolbox()
toolbox.register("individual", tools.initIterate, creator.Individual, create_individual)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", mutate)
toolbox.register("select", tools.selTournament, tournsize=3)
toolbox.register("evaluate", evaluate)

results_df = pd.DataFrame(columns=['Generation', 'Best_RMSE', 'Best_R2', 'Avg_RMSE', 'Avg_R2',
                                   'Selected_Features', 'Num_Features', 'Num_Additional_Features',
                                   'Additional_Features', 'Best_Individual'])

population = toolbox.population(n=100)
generations = 50
best_individual_overall = None
best_fitness_overall = (float('inf'), -float('inf'))

for gen in range(generations):
    offspring = toolbox.select(population, len(population))
    offspring = list(map(toolbox.clone, offspring))
    
    for child1, child2 in zip(offspring[::2], offspring[1::2]):
        if np.random.rand() < 0.7:
            toolbox.mate(child1, child2)
            del child1.fitness.values
            del child2.fitness.values
    
    for mutant in offspring:
        if np.random.rand() < 0.2:
            toolbox.mutate(mutant)
            del mutant.fitness.values
    
    invalid_individuals = [ind for ind in offspring if not ind.fitness.valid]
    fitnesses = list(map(toolbox.evaluate, invalid_individuals))
    for ind, fit in zip(invalid_individuals, fitnesses):
        ind.fitness.values = fit
    
    population[:] = offspring
    
    rmse_values = [ind.fitness.values[0] for ind in population]
    r2_values = [ind.fitness.values[1] for ind in population]
    avg_rmse = np.mean(rmse_values)
    avg_r2 = np.mean(r2_values)
    
    best_individual = tools.selBest(population, 1)[0]
    best_rmse, best_r2 = best_individual.fitness.values
    
    if best_rmse < best_fitness_overall[0] and best_r2 > best_fitness_overall[1]:
        best_individual_overall = best_individual.copy()
        best_fitness_overall = (best_rmse, best_r2)
    
    selected_features = [X_scaled.columns[i] for i in range(len(best_individual)) if best_individual[i] == 1]
    additional_features = get_additional_features(best_individual)
    num_features = len(selected_features)
    num_additional_features = len(additional_features)
    
    new_row = pd.DataFrame({
        'Generation': [gen],
        'Best_RMSE': [best_rmse],
        'Best_R2': [best_r2],
        'Avg_RMSE': [avg_rmse],
        'Avg_R2': [avg_r2],
        'Selected_Features': [', '.join(selected_features)],
        'Num_Features': [num_features],
        'Num_Additional_Features': [num_additional_features],
        'Additional_Features': [', '.join(additional_features)],
        'Best_Individual': [str(best_individual)]
    })
    results_df = pd.concat([results_df, new_row], ignore_index=True)
    
    if gen % 5 == 0 or gen == generations - 1:
        results_df.to_excel(f'ga_results_gen_{gen}.xlsx', index=False)

results_df.to_excel('ga_results_final.xlsx', index=False)

if best_individual_overall is not None:
    best_rmse, best_r2 = best_fitness_overall
    selected_features = [X_scaled.columns[i] for i in range(len(best_individual_overall)) if best_individual_overall[i] == 1]
    additional_features = get_additional_features(best_individual_overall)
else:
    selected_features = [X_scaled.columns[i] for i in range(len(best_individual)) if best_individual[i] == 1]
    additional_features = get_additional_features(best_individual)
